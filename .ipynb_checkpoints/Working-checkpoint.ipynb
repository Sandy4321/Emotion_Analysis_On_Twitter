{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import googlemaps # This had to be installed\n",
    "import twitter # This should already be installed (but was additional)   \n",
    "import urllib.parse as urllib\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import numpy as np\n",
    "import itertools as itr\n",
    "import re\n",
    "import string\n",
    "import random\n",
    "import time\n",
    "import datetime\n",
    "import csv\n",
    "import math\n",
    "from twitter import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Bokeh Packages\n",
    "from bokeh.layouts import row, column, widgetbox, layout\n",
    "from bokeh.models.widgets import Button, TextInput, Select, Div, DataTable, TableColumn, NumberFormatter, Panel, Tabs\n",
    "from bokeh.models import HoverTool, ColumnDataSource, GMapOptions\n",
    "from bokeh.plotting import show, figure, gmap\n",
    "from bokeh.io import show, push_notebook, output_notebook, reset_output\n",
    "from bokeh.application.handlers import FunctionHandler\n",
    "from bokeh.application import Application\n",
    "from bokeh.models.tiles import WMTSTileSource\n",
    "from bokeh.document import Document\n",
    "from bokeh.io import output_file, show\n",
    "from bokeh.models.widgets import CheckboxGroup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "CREDFILE = 'OAuth_Keys.json'\n",
    "GOOGLE_MAPS_API_URL = 'http://maps.googleapis.com/maps/api/geocode/json'\n",
    "RATE_LIMIT = 25\n",
    "NO_FETCHES=\"5\"\n",
    "LOADING_IMAGE = 'data/Wedges-3s-200px.gif'\n",
    "SAMPLEFILE = 'data/sentiment_sample.json'\n",
    "DEFAULT_GEO = 'Syracuse, NY'\n",
    "PADDING = 0.1\n",
    "APP_WIDTH = 650\n",
    "APP_HEIGHT = 700\n",
    "location = TextInput(value=\"Syracuse\", title='Search Location:',sizing_mode='scale_width')\n",
    "emoList = ['joy','fear','anger','sadness','disgust','shame','guilt','neutral']\n",
    "checkbox_group = CheckboxGroup(labels=emoList, active=[0, 1,2,3,4,5,6,7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from copy import copy\n",
    "import pickle\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "def build_dataset(df,emotion):\n",
    "    emotion_df = copy(df)\n",
    "    is_not_emotion = emotion_df.Emotion != emotion\n",
    "    emotion_df.loc[is_not_emotion, 'Emotion'] = 'no'+ emotion\n",
    "    print(emotion_df.Emotion.value_counts())\n",
    "    return emotion_df\n",
    "\n",
    "def stem_data(text_series):\n",
    "    stemmer = SnowballStemmer(\"english\", ignore_stopwords=True)\n",
    "    class StemmedCountVectorizer(CountVectorizer):\n",
    "        def build_analyzer(self):\n",
    "            analyzer = super(StemmedCountVectorizer, self).build_analyzer()\n",
    "            return lambda doc: ([stemmer.stem(w) for w in analyzer(doc)])\n",
    "    stemmed_count_vect = StemmedCountVectorizer(stop_words='english')\n",
    "    X_counts = stemmed_count_vect.fit_transform(text_series)\n",
    "    return X_counts,stemmed_count_vect\n",
    "\n",
    "def tfidf_transform(X_counts):\n",
    "    tfidf_transformer = TfidfTransformer()\n",
    "    X_tfidf = tfidf_transformer.fit_transform(X_counts)\n",
    "    print(X_tfidf.shape)\n",
    "    return X_tfidf,tfidf_transformer\n",
    "\n",
    "def over_sample(y, X_tfidf):\n",
    "    sm = SMOTE(random_state=42)\n",
    "    X_res, y_res = sm.fit_resample(X_tfidf, y)\n",
    "    unique, counts = np.unique(y_res, return_counts=True)\n",
    "    print(dict(zip(unique, counts)))\n",
    "    return X_res, y_res\n",
    "\n",
    "def classify(X, y):\n",
    "    print(\"Training the model\")\n",
    "    clf = RandomForestClassifier(n_estimators = 100).fit(X, y)\n",
    "    return clf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path\n",
    "def train_models(trainAll):\n",
    "    df = pd.read_csv('DATA.csv', dtype='str')\n",
    "    emotion_range = {'joy': 'model_joy.pkl', 'fear': 'model_fear.pkl', 'anger': 'model_anger.pkl', 'sadness': 'model_sadness.pkl',\n",
    "                    'disgust': 'model_disgust.pkl', 'shame': 'model_shame.pkl', 'guilt': 'model_guilt.pkl'}\n",
    "    \n",
    "    X_counts,stemmed_count_vect = stem_data(df.Text)\n",
    "    X_tfidf, tfidf_transformer = tfidf_transform(X_counts)\n",
    "       \n",
    "    for emo, filename in emotion_range.items():\n",
    "        if ((not os.path.isfile(filename)) or trainAll):\n",
    "            emotion_df = build_dataset(df, emo)\n",
    "            X, y = over_sample(emotion_df.Emotion, X_tfidf)\n",
    "            model = classify(X, y)\n",
    "            with open(filename, 'wb') as file:  \n",
    "                pickle.dump(model, file)\n",
    "    return stemmed_count_vect, tfidf_transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#main classification function which is called by the ui function\n",
    "def emotion_Classifier(dataset):\n",
    "    emotion_range = {'joy': 'model_joy.pkl', 'fear': 'model_fear.pkl', 'anger': 'model_anger.pkl', 'sadness': 'model_sadness.pkl',\n",
    "                        'disgust': 'model_disgust.pkl', 'shame': 'model_shame.pkl', 'guilt': 'model_guilt.pkl'}\n",
    "    result_dict = {'joy':0, 'fear':0, 'anger':0, 'sadness':0, 'disgust':0, 'shame':0, 'guilt':0, 'neutral':0}\n",
    "    stemmed_count_vect, tfidf_transformer = train_models(False)\n",
    "    \n",
    "    regex_tags = [r'@\\w+',r'']\n",
    "    regex_hashtag = [r'#\\w+',r'']\n",
    "    dataset.insert(2, 'emotion', value = None)\n",
    "    \n",
    "    pickle_model = {}\n",
    "    for emo, filename in emotion_range.items():\n",
    "        with open(filename, 'rb') as file:\n",
    "            pickle_model[emo] = pickle.load(file)\n",
    "            \n",
    "    for index, row in dataset.iterrows():\n",
    "        input_array = row.text\n",
    "        input_array = re.sub(regex_tags[0], regex_tags[1],input_array)\n",
    "        input_array = re.sub(regex_hashtag[0], regex_hashtag[1],input_array)\n",
    "        input_series = pd.Series(input_array)\n",
    "        X_counts = stemmed_count_vect.transform(input_series)\n",
    "        X_counts = tfidf_transformer.transform(X_counts)\n",
    "        prediction_probabilities = {}\n",
    "        \n",
    "        for emo, filename in emotion_range.items():\n",
    "            prob = pickle_model[emo].predict_proba(X_counts)\n",
    "            pred = pickle_model[emo].predict(X_counts)\n",
    "            prediction_probabilities[pred[0]] = np.max(prob)\n",
    "        result = max(prediction_probabilities, key=lambda key: prediction_probabilities[key] if 'no' not in key else 0)\n",
    "        result = result if 'no' not in result else 'neutral'\n",
    "        result_dict[result] += 1\n",
    "        dataset.loc[index].emotion = result\n",
    "    return result_dict, dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#helperfunction to process the keys from authetication file\n",
    "def getKeys(filename):\n",
    "    with open(filename,'r') as fd:\n",
    "        keys = json.load(fd)\n",
    "    return keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = getKeys(CREDFILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initGoogle():\n",
    "    gmaps = googlemaps.Client(key=keys['GoogleKey'])\n",
    "    return gmaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initTwitter():\n",
    "     api = twitter.Api(consumer_key = keys['Key'], \n",
    "                consumer_secret = keys['SKey'], \n",
    "                access_token_key = keys['Token'], \n",
    "                access_token_secret = keys['SToken'],\n",
    "                sleep_on_rate_limit=True)\n",
    "    \n",
    "    return api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#update of ui\n",
    "def manageUi(pieChart,graph,table):\n",
    "    \n",
    "    if graph == None:\n",
    "          graph = Div(text='<div align=\"center\" style=\"display:block\"><h2>None of the tweets have location coordinates enabled</h2><br><br><br></div>', width=500)\n",
    "          \n",
    "    emoList = ['joy','fear','anger','sadness','disgust','shame','guilt','neutral']\n",
    "    tab1 = Panel(child=graph, title=\"map\")\n",
    "    tab2 = Panel(child=pieChart, title=\"Pie chart\")\n",
    "    tab3 = Panel(child=table, title=\"Table\")\n",
    "    tabs = Tabs(tabs=[ tab1, tab2,tab3 ])\n",
    "    location = TextInput(value=\"Syracuse\", title='Search Location:',sizing_mode='scale_width')\n",
    "    submit = Button(label='Process Tweets', button_type='success')\n",
    "    processEmoB = Button(label='Process Emotions', button_type='success')\n",
    "    processEmoB.on_click(update)\n",
    "    show(row(column(location,submit,widgetbox(checkbox_group),processEmoB),tabs))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initializeUi():\n",
    "    output_file(\"Working.html\")\n",
    "    reset_output()\n",
    "    update()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rawQuery(lat, long, radius):\n",
    "    raw =[lat,long,radius+\"mi\"]\n",
    "    return raw\n",
    "#this helper method returns the geocode\n",
    "def geocode(loc, api):\n",
    "    result = api.geocode(loc)\n",
    "    if (result):\n",
    "        result = result[0]['geometry']['location']\n",
    "    else:\n",
    "        result = None\n",
    "    return result\n",
    "\n",
    "\n",
    "#table creation to output emotion:tweet\n",
    "def tableCreation(emoDataDic,value):\n",
    "    emoList = ['joy','fear','anger','sadness','disgust','shame','guilt','neutral']\n",
    "    value2 =list()\n",
    "    tweetList =list()\n",
    "    emotionList =list()\n",
    "    while(len(value)) !=0:\n",
    "        value2.append(value.pop(0))\n",
    "    for j in value2 :\n",
    "        for index, r in emoDataDic[emoList[j]].iterrows():\n",
    "            tweetList.append(r[\"text\"])\n",
    "            emotionList.append(r[\"emotion\"])\n",
    "    data = dict(Tweet=tweetList,Emotion=emotionList)       \n",
    "    source = ColumnDataSource(data)\n",
    "    columns = [\n",
    "        TableColumn(field=\"Tweet\", title=\"Tweet\"),\n",
    "        TableColumn(field=\"Emotion\", title=\"Emotion\"),]\n",
    "    data_table = DataTable(source=source, columns=columns, width=1100,fit_columns=False,height=500)\n",
    "    return widgetbox(data_table)\n",
    "\n",
    "#process the twitter query\n",
    "def processQuery(api, raw):\n",
    "    switch = 1\n",
    "    i = 0\n",
    "    tweets = list();\n",
    "    while (switch == 1):\n",
    "        results = api.GetSearch(raw_query = raw, return_json=True)\n",
    "        i += 1\n",
    "        tweets.append(results)\n",
    "        if ('next_results' in results['search_metadata'].keys()):\n",
    "            raw = results['search_metadata']['next_results']\n",
    "            temp = raw[1:].split('&q=')\n",
    "            raw = '&q=' + temp[1] + '&' + temp[0]\n",
    "        else:\n",
    "                switch = 0\n",
    "        \n",
    "        if (i == RATE_LIMIT):\n",
    "            switch = 0\n",
    "    \n",
    "    return tweets\n",
    "#extract data from the tweeter raw output received\n",
    "def extractData(results):\n",
    "    records = list()\n",
    "    labels = ['text','geo']\n",
    "    k=0\n",
    "    for i in range(len(results)):\n",
    "        for j in range(len(results[i]['statuses'])):\n",
    "            if ('text' not in results[i]['statuses'][j].keys()):\n",
    "                    text = results[i]['statuses'][j]['full_text']\n",
    "                    \n",
    "            else:\n",
    "                text = results[i]['statuses'][j]['text'] \n",
    "            geo = results[i]['statuses'][j]['geo'] \n",
    "            records.append([text,geo])\n",
    "    datasets = pd.DataFrame.from_records(records, columns = labels)   \n",
    "    return datasets  \n",
    "\n",
    "#plotting the piechart\n",
    "def piechart(emoPieChart):\n",
    "    data = pd.Series(emoPieChart).reset_index(name='value').rename(columns={'index':'emotion'})\n",
    "    data['angle'] = data['value']/data['value'].sum() * 2*pi\n",
    "    data['color'] = Category20c[len(emoPieChart)]\n",
    "\n",
    "    plot = figure(plot_height=350, title=\"Pie Chart\", toolbar_location=None,\n",
    "                tools=\"hover\", tooltips=\"@emotion: @value\")\n",
    "    plot.wedge(x=0, y=1, radius=0.4,\n",
    "                start_angle=cumsum('angle', include_zero=True), end_angle=cumsum('angle'),\n",
    "                line_color=\"white\", fill_color='color', legend='emotion', source=data)\n",
    "    return plot \n",
    "    \n",
    "\n",
    "def plotGeo(dataset,latLong):\n",
    "    map_options = GMapOptions(lat=latLong[\"lat\"], lng=latLong[\"lng\"], map_type=\"roadmap\", zoom=11)\n",
    "    sMap = gmap(keys['GoogleKey'], map_options, title=\"Map\")\n",
    "    emotionList = [\"joy\",\"fear\",\"anger\",\"sadness\",\"disgust\",\"shame\", \"guilt\",\"neutral\"]\n",
    "    emoColourDict = {\"joy\":\"red\",\"fear\":\"blue\",\"anger\":\"black\",\"sadness\":\"red\",\"disgust\":\"green\",\"shame\":\"grey\", \"guilt\":\"red\",\"neutral\":\"blue\"}\n",
    "    emoCoordDict ={} #dic of emotion to list(lat and longitude)\n",
    "    emoPieChart ={}\n",
    "    emoDataDict ={} #dic of emotion to dataset\n",
    "    for i in emotionList:\n",
    "        emoDataDict[i] = dataset[dataset['emotion'] == i]\n",
    "        emoPieChart[i]=len(emoDataDict[i])\n",
    "       #loop through emotion list to make a emotion:coordinate dictionary\n",
    "    for i in emotionList:\n",
    "        theList = list(filter(None, emoDataDict[i]['geo']))\n",
    "        if len(theList)!=0:\n",
    "            emoCoordDict[i] =list()\n",
    "            for k in range(len(theList)):\n",
    "                emoCoordDict[i].append(theList[k]['coordinates'])\n",
    "           \n",
    "    latList =list()\n",
    "    longList =list()\n",
    "    if len(emoCoordDict)!=0:\n",
    "        print(emoCoordDict)\n",
    "        # loop through a dict{emotion:correspondingdataset}to get the list of latitudes and longitudes to be sent to the map object\n",
    "        for i in emoCoordDict.keys():\n",
    "            \n",
    "            for j in range(len(emoCoordDict[i])):\n",
    "                latList.append(emoCoordDict[i][j][0])\n",
    "                longList.append(emoCoordDict[i][j][1])\n",
    "            source = ColumnDataSource(\n",
    "            data=dict(lat=latList,\n",
    "              lon=longList))\n",
    "            sMap.circle(x=\"lon\", y=\"lat\", size=15, fill_color=emoColourDict[i], fill_alpha=0.5, source=source)\n",
    "    return emoPieChart,emoDataDict,sMap  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from math import pi\n",
    "\n",
    "import pandas as pd\n",
    "from bokeh.io import output_file, show\n",
    "from bokeh.palettes import Category20c\n",
    "from bokeh.plotting import figure\n",
    "from bokeh.transform import cumsum\n",
    "from bokeh.models import Button\n",
    "from bokeh.plotting import figure, curdoc\n",
    "\n",
    "def update(): \n",
    "    loc = \"syracuse\"\n",
    "    emotions = list()\n",
    "    value=checkbox_group.active\n",
    "    #creating a list of a bokeh list type\n",
    "    while len(value)!=0:\n",
    "        emotions.append(value)\n",
    "    tAPI = initTwitter()\n",
    "    gAPI = initGoogle()\n",
    "    latlong = geocode(loc, gAPI)\n",
    "    raw='q=geocode%3A' + str(latlong['lat']) + '%2C' + str(latlong['lng']) + '%2C' + \"5mi\" + '&lang=en&result_type=recent&include_entities=true&count=50&tweet_mode=extended'\n",
    "    results = processQuery(tAPI, raw)\n",
    "    dataset = extractData(results)\n",
    "    time.sleep(5)\n",
    "    result_dict, dataset = emotion_Classifier(dataset)\n",
    "    emoPieChart,emoDataDict,map = plotGeo(dataset,latlong)\n",
    "    pieChartVar =piechart(emoPieChart)  \n",
    "    tableVar=tableCreation(emoDataDict,emotions)\n",
    "    manageUi(pieChartVar,map,tableVar)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#main function that runs the entire program\n",
    "initializeUi() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
